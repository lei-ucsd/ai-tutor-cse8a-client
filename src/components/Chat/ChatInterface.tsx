import "./index.css";
import React, { useEffect } from "react";
import { Paper } from "@mui/material";
import { TextInput } from "./TextInput";
import { MessageOther, MessageSelf } from "./Message";
import { useState } from "react";
import { ChatRequest, ChatResponseStream, getResponse, Message } from "@site/src/utils";
import { QuestionRequestStream, ChatHistory } from "@site/src/utils/data-model";
import { getQuestion } from "@site/src/utils/chat-utils";
import { QUESTIONS } from "@site/src/initialQuestions";


const initRawMsgs: Message[] = [
    {
        type: 'bot',
        message: 'Hello! I am your personalized AI tutor. Let me help you with any question you might have for this course.'
    }
]

const initMsgs = [
    <MessageOther
        message={'Hello! I am your personalized AI tutor. Let me help you with any question you might have for this course.'}
        timestamp=""
        displayName="AI Tutor"
        avatarDisp={true}
    />
]

// the back end supports up to `analyze' at the moment
const bloomsTaxonomy = ['remember', 'understand', 'apply', 'analyze'];


// hard-coded threshold for all steps
const THRESHOLD = 3;

// hard-coded concept for review
// TODO: going forward, the concept should be determined by the user's input at the beginning of a conversation
const CONCEPT = 'conditionals';

// initial questions for the chosen concept
const initQuestions = QUESTIONS[CONCEPT];

const BRIDGES = [
    `Here's a practice question to help you with `,
    `Let's practice `,
    `Let's work on `,
]


export default function ChatInterface() {

    // current level of the bloom's taxonomy determined by the AI, default to undefined
    const [questionLevel, setQuestionLevel] = useState(undefined);

    // last question the AI asked the user, default to undefined
    const [lastQuestion, setLastQuestion] = useState(undefined);

    // raw representation of the chat messages
    const [rawMsgs, setRawMsgs] = useState(initRawMsgs);

    // rendered representation of the chat messages
    // TODO: this will be refactored out; we will only use rawMsgs and its mapping at rendering time
    const [msgs, setMsgs] = useState(initMsgs);

    // raw representation of the AI's response streamed from the server
    // using an array to store all intermediate responses to avoid losing any data during streaming
    const [rawResponseData, setRawResponseData] = useState([]);

    // a JSON object that is the raw representation of the questions generated by the server
    // each key corresponds to a level of the bloom's taxonomy, the value of which is an array of questions at that level
    const [rawQuestionData, setRawQuestionData] = useState(initQuestions);

    // number of correct responses at a given level
    const [correctSoFar, setCorrectSoFar] = useState(0);

    // a boolean flag to indicate whether the user has just reset the conversation via upload
    // only set to `true` after uploading a history file
    const [justReset, setJustReset] = useState(false);


    // We use a `useEffect' hook to enable the following side effect
    // without any rerendering
    // only when the value of `lastQuestion` is changed,
    // i.e., when one question at a level is used:
    // We will request the backend to generate a one new question for that level
    useEffect(() => {
        if (lastQuestion && lastQuestion.length > 0) {
            getNewQuestionByLevel(questionLevel, rawQuestionData[questionLevel])
                .then((res) => {
                    const newRawQuestionData = {
                        ...rawQuestionData
                    };
                    newRawQuestionData[questionLevel].push(res);
                    setRawQuestionData(newRawQuestionData);
                })
                .catch((err) => {
                    console.error(err);
                    // don't do anything if the request fails
                });
        }
    }, [lastQuestion]);

    // We use a `useEffect' hook to enable the following side effect
    // only when the values of `questionLevel` and `correctSoFar` are both changed,
    // i.e., when the user answered a question correctly or moved onto a new question level:
    // we show a (already generated) new question when a new level is reached, or when a question at a given level is completed
    useEffect(() => {
        const question = getQuestionToShow(questionLevel, rawQuestionData);
        if (!justReset && question && correctSoFar < THRESHOLD) {
            console.log('question: ', question);
            // TODO: typewriter effect?

            // final rendering and setting states
            const bridge = getBridgeMsg(questionLevel, CONCEPT, correctSoFar === 0);
            const _ = updateMsgList(bridge + question, 'AI Tutor', rawMsgs, msgs, setMsgs, setRawMsgs);

            setLastQuestion(question);
        }
    }, [questionLevel, correctSoFar]);


    const addMsg = async (msg: string) => {

        if (msg.trim().length === 0) {
            alert('Please enter a non-empty message.');
            return;
        }

        const req: ChatRequest = {
            user: "kayla",
            password: "lei",
            timestamp: Date.now(),
            message: msg,
            correctSoFar: correctSoFar,
            threshold: THRESHOLD,
        }

        // TODO refactor out
        if (questionLevel) {
            req.current_step = questionLevel;
        }

        const newMsgs: Message[] = [
            ...rawMsgs,
            {
                type: 'user',
                message: msg
            }
        ];


        req.history = getHistory(newMsgs);

        const newRenderedMsgs = [
            <MessageSelf
                message={msg}
                timestamp=""
                displayName="User"
                avatarDisp={false}
            />,
            ...msgs
        ]

        setMsgs(newRenderedMsgs);

        getResponse(req, lastQuestion ?? '', setRawResponseData)
            .then((res) => {
                if ('tutor_response' in res && res.tutor_response !== '') {
                    // clear the justReset flag if it has been set
                    setJustReset(false);

                    const msg = renderTutorResponseFinal(res.tutor_response, res.follow_up_question, res.question_completed, questionLevel);

                    const [msgElems, msgData] = updateMsgList(msg, 'AI Tutor', newMsgs, newRenderedMsgs, setMsgs, setRawMsgs);

                    setRawResponseData([]);


                    let newCorrectSoFar = correctSoFar;

                    // track correctness if current question is completed
                    // then the useEffect hook will show the next question on the level if threshold has not been met
                    if (questionLevel && res.question_completed === "true") {
                        newCorrectSoFar += 1;
                        setCorrectSoFar(newCorrectSoFar);
                    }

                    // update current level if correctSoFar reaches threashold
                    if (newCorrectSoFar === THRESHOLD) {
                        const idxCurrent = bloomsTaxonomy.indexOf(questionLevel);
                        const idxNew = idxCurrent + 1;
                        if (idxNew === bloomsTaxonomy.length) {
                            // the backend only reasonably supports steps up to `analyze` or whichever is the last step; 
                            // however, user might reach `create` if their first question is determined to be at that level
                            // we should end the conversation whenever (1) the step naturally reaches beyond 'analyze' or (2) the user finishes 'create'

                            const msg = 'Congratulations! You have successfully completed reviewing the concept! Would you like to review another concept?';
                            const _ = updateMsgList(msg, 'AI Tutor', msgData, msgElems, setMsgs, setRawMsgs);

                            // reset question level
                            setQuestionLevel(undefined);
                        } else {
                            // the useEffect hook will automatically show a new question at the new level 
                            const idx = bloomsTaxonomy.indexOf(questionLevel);
                            const newStep = bloomsTaxonomy[idx + 1];
                            setQuestionLevel(newStep);
                            setCorrectSoFar(0);
                        }
                    }

                    // only initialize question Level if it is not set yet;
                    if (!questionLevel && res.question_level !== "") {
                        setQuestionLevel(res.question_level);
                    }
                } else {
                    alert('No tutor response received. Please try again.')
                }

            })
            .catch((err) => {
                console.error(err);
            });


    }


    /**
     * Save chat history and related informaiton to a JSON file.
     * @param filename Filename for the JSON file to be downloaded.
     */
    const saveHistory = (filename: string) => {
        const data = {
            msgs: rawMsgs,
            questionLevel: questionLevel ?? 'undefined',
            lastQuestion: lastQuestion ?? 'undefined',
            correctSoFar: correctSoFar,
            rawQuestionData: rawQuestionData,
        };

        const downloadableData = encodeURIComponent(JSON.stringify(data, null, 2));
        const element: HTMLAnchorElement = document.getElementById('save-chat-history') as HTMLAnchorElement;

        element.href = `data:application/json;charset=utf-8,${downloadableData}`;
        element.download = filename;
        element.click();
    }

    /**
     * Restore chat history and related information from a parsed JSON object.
     * @param data a parsed JSON object that contains chat history and related information.
     */
    const loadHistory = (data: ChatHistory) => {
        const msgs: Message[] = data.msgs;
        const questionLevel: string = data.questionLevel;
        const lastQuestion: string = data.lastQuestion;
        const correctSoFar: number = data.correctSoFar;
        const rawQuestionData = data.rawQuestionData;

        setJustReset(true);
        setRawMsgs(msgs);
        setMsgs(msgs.slice(0).reverse().map((msg: Message) => {
            if (msg.type === 'bot') {
                return (
                    <MessageOther
                        message={msg.message}
                        timestamp=""
                        displayName="AI Tutor"
                        avatarDisp={true}
                    />
                );
            } else {
                return (
                    <MessageSelf
                        message={msg.message}
                        timestamp=""
                        displayName="User"
                        avatarDisp={false}
                    />
                );
            }
        }));

        setQuestionLevel(questionLevel === 'undefined' ? undefined : questionLevel);
        setLastQuestion(lastQuestion === 'undefined' ? undefined : lastQuestion);
        setCorrectSoFar(correctSoFar);
        setRawQuestionData(rawQuestionData);
    }


    return (
        <div className="chatContainer" key="chat-container">
            <Paper className="paper" elevation={0}>
                <Paper id="style-1" className="messagesBody" key="messages-body">
                    <div className="messages" key="messages">
                        {/* most recent AI message */}
                        {

                            rawResponseData.length > 0 ?
                                <MessageOther
                                    message={renderTutorResponseRealTime(rawResponseData)}
                                    timestamp=""
                                    displayName="AI Tutor"
                                    avatarDisp={true}
                                    key="ai-msg"
                                />
                                : <></>
                        }
                        {msgs}
                    </div>
                </Paper>
                {
                    rawQuestionData ?
                        <TextInput onAddMsg={addMsg} onSaveHistory={saveHistory} onLoadHistory={loadHistory} /> :
                        <h3>Initializing the chat. Please wait...</h3>
                }
            </Paper>
        </div>
    )
}


/**
 * Get the history of the conversation in a string format.
 * @param msgs A list of messages in their raw representation forms ordered chronologically.
 * @returns A string concatenating all messages and their roles in the list.
 */
function getHistory(msgs: Message[]) {
    let history = "\n";
    for (let i = 0; i < msgs.length; i++) {
        const msg = msgs[i];
        if (msg.type === 'bot') {
            history += "tutor: " + msg.message + "\n";
        } else {
            history += "student: " + msg.message + "\n";
        }
    }

    return history;
}


/**
 * Used to return the most recent AI response in real time for streaming effect.
 * @param data A list of JSON/ChatResponseStream objects representing the AI's response to the user's input.
 * @returns The `tutor_response' field of the most recent JSON/ChatResponseStream object in the list.
 */
function renderTutorResponseRealTime(data: ChatResponseStream[]) {
    const tutorResponse = data[data.length - 1].tutor_response;
    return tutorResponse;
}


/**
 * Used to return the final AI response to the user's input.
 * @param tutorResponse The `tutor_response` field of the last JSON/ChatResponseStream object.
 * @param followUpQuestion The `follow_up_question` field of the last JSON/ChatResponseStream object.
 * @param questionCompleted The `question_completed` field of the last JSON/ChatResponseStream object.
 * @param questionLevel Current value of the stateful variable `questionLevel`.
 * @returns A string that is the final rendering of the AI's response to the user's input, 
 *          optionally including the follow-up question if the current question is not completed
 *          and the current question level is valid.
 */
function renderTutorResponseFinal(tutorResponse: string, followUpQuestion: string, questionCompleted: string, questionLevel: string | undefined) {
    if (followUpQuestion !== '' && (questionCompleted === 'false' && questionLevel)) {
        return tutorResponse + '\n\n' + followUpQuestion;
    } else {
        return tutorResponse;
    }
}


/**
 * Used to return the most recent question at a given level when applicable.
 * @param questionLevel The current value of the stateful variable `questionLevel`.
 * @param rawQuestionData The current value of the stateful variable `rawQuestionData`, 
 *                          which, if defined, is a JSON object where the keys are valid bloom's levels,
 *                           and the values are lists of AI-generated questions for that level.
 * @returns The most recent question at the given level, or undefined if the level is invalid or there are no questions at that level.
 */
function getQuestionToShow(questionLevel: string | undefined, rawQuestionData: { [key: string]: string[] } | undefined) {
    // do not show question when there are no initial questions or no questions at a given level
    if (!rawQuestionData || !questionLevel || !(questionLevel in rawQuestionData) || rawQuestionData[questionLevel].length === 0) {
        return undefined;
    }

    // show the most recent question at a given level
    const questions = rawQuestionData[questionLevel];
    return questions[questions.length - 1];
}


/**
 * Used to update the rendered and raw representations for the chat history.
 * @param msg A string that represents the most recent message to be added to the chat history UI.
 * @param role The role that the message belongs to, either 'AI Tutor' or 'User'.
 * @param msgData Raw data representation for the chat history.
 * @param existingMsgElems Rendered representation for the chat history.
 * @param setMsgs React hook for updating the rendered representation for the chat history.
 * @param setRawMsgs React hook for updating the raw data representation for the chat history.
 * @returns A two-element list, where the first element is the updated rendered representation for the chat history,
 *          and the second element is the updated raw data representation for the chat history.
 */
// TODO: use (reverse) mapping to render raw messages into JSX elements
function updateMsgList(
    msg: string,
    role: string,
    msgData: Message[],
    existingMsgElems: React.JSX.Element[],
    setMsgs: (msgs: React.JSX.Element[]) => void,
    setRawMsgs: (msgs: Message[]) => void
): [React.JSX.Element[], Message[]] {

    const msgElem = role === "AI Tutor" ?
        (
            <MessageOther
                message={msg}
                timestamp=""
                displayName="AI Tutor"
                avatarDisp={true}
            />
        ) : (
            <MessageSelf
                message={msg}
                timestamp=""
                displayName="User"
                avatarDisp={false}
            />
        );

    msgData.push({
        type: role === "AI Tutor" ? 'bot' : 'user',
        message: msg
    });

    const newMsgElems = [
        msgElem,
        ...existingMsgElems
    ];

    setMsgs(
        newMsgElems
    );

    setRawMsgs(msgData);

    return [newMsgElems, msgData];
}


/**
 * Used to request a new question from the backend.
 * @param level The level of the bloom's taxonomy for which a new question is to be requested.
 * @param previousQuestions A list of questions that have been asked at the given level.
 * @returns A new question at the given level.
 */
async function getNewQuestionByLevel(level: string, previousQuestions: string[]) {
    const questionReq: QuestionRequestStream = {
        bloom_level: level,
        previous_questions: previousQuestions,
        include_prefix: true
    }
    return await getQuestion(questionReq);
}


function getBridgeMsg(questionLevel: string, concept: string, firstQuestion: boolean) {
    const template = BRIDGES[Math.floor(Math.random() * BRIDGES.length)];
    const level = questionLevel === 'analyze' ? 'analyzing' : `${questionLevel}ing`;
    const again = firstQuestion ? '' : ' again';
    const bridge = `${template}${level} ${concept}${again}.\n\n`;
    return bridge;
}
